{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最好首先对数据进行可视化，这样分为多少个类心里有个印象\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 自己创建数据集\n",
    "X, y = make_blobs(n_samples=500, n_features=2, centers=4, random_state=1)\n",
    "# 生成1个子图，fig是画布，ax1是对象\n",
    "fig, ax1 = plt.subplots(1)\n",
    "ax1.scatter(X[:, 0], X[:, 1]\n",
    "            ,marker=\"o\" # 点的形状\n",
    "            ,s=8 # 点的大小\n",
    "            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 3\n",
    "\n",
    "cluster = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "\n",
    "# 重要的属性labels_, 查看聚类好的类别，每个样本所对应的类\n",
    "y_pred = cluster.labels_\n",
    "y_pred\n",
    "# kmeams并不需要建立模型或者预测结果，因此我们只需要fit就能得到聚类结果了\n",
    "# 也有predict表示学习数据x并对x的类进行预测,但是和我们的labels属性结果相同\n",
    "pre = cluster.fit_predict(X)\n",
    "pre == y_pred\n",
    "# 当数据量很大时，就需要predict，可以先用切片，切少量的样本，用fit找到质心，之后再将所有数据带入跑，就会比较好,比如很多万行\n",
    "cluster_smallsub = KMeans(n_clusters=n_clusters, random_state=0).fit(X[:200])\n",
    "y_pred_ = cluster_smallsub.predict(X)\n",
    "# 查看质心\n",
    "centroid = cluster.cluster_centers_\n",
    "centroid\n",
    "\n",
    "# 查看总距离的平方和\n",
    "inertia = cluster.inertia_\n",
    "inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [\"red\", \"pink\", \"orange\", \"gray\"]\n",
    "fig, ax1 = plt.subplots(1)\n",
    "for i in range(n_clusters):\n",
    "    ax1.scatter(X[y_pred==i, 0], X[y_pred==i, 1]\n",
    "                ,marker=\"o\"\n",
    "                ,s=8\n",
    "                ,c=color[i])\n",
    "ax1.scatter(centroid[:, 0], centroid[:, 1]\n",
    "            ,marker=\"x\"\n",
    "            ,s=15\n",
    "            ,c=\"black\")\n",
    "plt.show()\n",
    "# 接下来可以改变n_cluster，来看看，发现平方和不是评价指标，毕竟取500 的平方和是0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何评价聚类呢，无法确定，只能是根据业务来看，inartia没有界，对模型本身是好不好，而且本身容易受到特征数目的影响，会陷入维度诅咒，会受到超参数k的影响，而且假设是个凸分布\n",
    "# 使用轮廓系数\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "# 把数据和对应的预测类别带入进行分析\n",
    "silhouette_score(X, y_pred)\n",
    "# 平均的样本轮廓系数\n",
    "silhouette_score(X, cluster.labels_)\n",
    "# 每个样本自己的轮廓系数\n",
    "silhouette_samples(X, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  另一个评价指数\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "calinski_harabaz_score(X, y_pred)\n",
    "# 为了计算速度，有%%timeit 魔法方法\n",
    "# 这里我们用另一种计算时间的方法，时间戳计算运行速度\n",
    "from time import time\n",
    "# time(),记下每一次time（）命令的时间戳\n",
    "t0 = time()\n",
    "calinski_harabaz_score(X, y_pred)\n",
    "time() - t0\n",
    "\n",
    "t0 = time()\n",
    "silhouette_score(X, y_pred)\n",
    "time() - t0\n",
    "# 时间戳可以通过datatime中的函数转换为真正的时间格式\n",
    "import datetime\n",
    "datetime.datetime.fromtimestamp(t0).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #colormap\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于我们的轮廓曲线选择最佳的n_clusters\n",
    "# 知道每个聚出来的类的轮廓系数是多少，还想要一个各个类之间的轮廓系数的对比\n",
    "# 知道聚类完毕之后的图像的分布是什么摸样\n",
    "# fig 是画布生成的画布对象，ax1是图像\n",
    "\n",
    "n_clusters = 4\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "# 第一个图是我们的轮廓系数图像，是由各个蹙的轮廓系数组成的横向条形图、\n",
    "# 横坐标是轮廓系数的取值， 纵坐标是我们的每个样本\n",
    "# 首先设定纵坐标，轮廓系数在-1， 1之间，但我们希望是大于零de\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "# 我们希望不同的簇之间有一定的空间，以便我们看到不同的条形图聚合成的块，理解她是对应了哪一个簇，因此多加了(n_clusters + 1) * 10\n",
    "ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 10])\n",
    "# 开始建模，调用聚类好的标签\n",
    "clusterer = KMeans(n_clusters=n_clusters, random_state=10).fit(X)\n",
    "cluster_labels = clusterer.labels_\n",
    "# 生成所有样本的轮廓系数的均值\n",
    "silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "print(\"for n_clusters = \", n_clusters,\n",
    "        \"the average silhouette score is\", silhouette_avg)\n",
    "# 调用silhouette_samples,返回每个样本点的轮廓系数，知识我们的横坐标\n",
    "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "# 开始画图\n",
    "# 设定y轴上的初始值\n",
    "y_lower = 10\n",
    "# 对每个簇进行循环\n",
    "for i in range(n_clusters):\n",
    "    # 从每个样本的轮廓系数结果中抽取第i个簇的轮廓系数，并对他进行排序\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "    # 注意.sort()会直接改掉原数据的顺序, 令他是从小到大的顺序\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    # 查看这个簇中有多少样本\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    # 这个簇在y轴上的取值\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    #colormap库中的，使用小数来调节颜色的函数\n",
    "    # nipy_spectrol(输入任意一个小数代表颜色)\n",
    "    # 我们希望每个簇的颜色不一样，我们需要的颜色种类刚好是循环的个数的种类，在这里，我们只要保证每次循环生成的小数是不同的，可以使用任意方式来获取小数\n",
    "    # 我是用i的浮点数除以n_clusters，在不同的i下，自然生成不同的小数\n",
    "    # 以确保不同的簇有不同的形状\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "\n",
    "    # 开始补充一图中的内容，fill_between是让一个范围中的柱状图都统一颜色的函数\n",
    "    # fill_betweenx的范围是在纵坐标上\n",
    "    # fill_betweeny的范围实在横坐标上\n",
    "    # fill_betweenx的参数应该输入（纵坐标的下线， 纵坐标的上限，x轴上的取值， 柱状图的颜色）\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                        ,ith_cluster_silhouette_values\n",
    "                        ,facecolor=color\n",
    "                        ,alpha=0.7 # 透明度\n",
    "    )\n",
    "    # 为灭个簇的轮廓系数写上簇的编号，并且让粗的编号显示坐标轴上每个条形图的中间位置\n",
    "    # text的参数为（要显示编号的位置的横坐标，要显示编号的位置的纵坐标，要显示的编号内容）\n",
    "    ax1.text(-.05\n",
    "            ,y_lower + 0.5 * size_cluster_i\n",
    "            ,str(i))\n",
    "    # 为下一个簇计算新的y轴上的初始值，是每一次迭代之后，y的上限再加上10\n",
    "    # 以此来保证，不同的簇的图像之间显示有空隙\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "# 给图1加上\n",
    "ax1.set_title(\"the silhouette plot for the various clusters\")\n",
    "ax1.set_xlabel(\"the silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"cluster label\")\n",
    "# 把整个数据集中的轮廓系数的均值以虚线的形式放入我们的图中\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "# 让y轴不显示任何刻度\n",
    "ax1.set_yticks([])\n",
    "# 让x轴上的刻度显示为我们规定的列表\n",
    "ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "# 开始对第二个图进行操作,画出聚类的样子， 首先获取颜色，由于这里没有循环，因此我们需要一次性生成多个小数来获取多个颜色\n",
    "# astype转化数据为浮点数，0， 1， 2， 3里面总共有四种颜色\n",
    "colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "ax2.scatter(X[:, 0], X[:, 1]\n",
    "            ,marker=\"o\" # 点的形状\n",
    "            ,s=8 # 点的大小 \n",
    "            ,c=colors\n",
    "            )\n",
    "# 把生成的质心放到图像里去\n",
    "centers = cluster.cluster_centers_\n",
    "# draw white circles at cluster centers\n",
    "ax2.scatter(centers[:, 0], centers[:, 1], marker=\"x\", \n",
    "            c=\"red\", alpha=1, s=200)\n",
    "# 为图二设置标题\n",
    "ax2.set_title(\"the visualization of the clustered data\")\n",
    "ax2.set_xlabel(\"feature space for the 1st feature\")\n",
    "ax2.set_ylabel(\"feature space for the 2nd feature\")\n",
    "\n",
    "# 为整个图设置标题\n",
    "plt.suptitle(\"silhouette analysis for kmeans clustering on sample data\"\n",
    "            \"with n_cluster = %d\" % n_clusters,\n",
    "            fontsize=14, fontweight=\"bold\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 之后把上面的代码包装成为一个大循环，设置n_cluster 为2， 3，4 5，6再循环\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看一看random，对于选择初始质心的影响\n",
    "\n",
    "plus = KMeans(n_clusters=10).fit(X)\n",
    "plus.n_iter_\n",
    "# 10，迭代次数少\n",
    "random = KMeans(n_clusters = 10, init=\"random\",random_state=420).fit(X)\n",
    "random.n_iter_\n",
    "# 19，迭代次数多\n",
    "\n",
    "\n",
    "#有k_means函数\n",
    "from sklearn.cluster import k_means\n",
    "k_means(X, 1, return_n_iter=True)\n",
    "# return_n_iter 默认是false,可以查看返回的最佳迭代次数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 案例，聚类算法用于降维，kmeans的矢量量化,非结构数据是图像声音等等，是一种降维算法\n",
    "# 矢量量化实在同等样本量上压缩信息大小\n",
    "# 一张图片上的信息被聚类到了几个质心附近，然后利用质心的性质去代替这个簇里面的所有样本的性质\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "# 对两个序列中的点进行距离匹配的函数\n",
    "from sklearn.datasets import load_sample_image\n",
    "# 导入图片数据所用的类\n",
    "from sklearn.utils import shuffle # 洗牌\n",
    "# 打乱有序的东西\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = load_sample_image(\"china.jpg\") # 三维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china.shape # 427*640里面的rgb三个特征\n",
    "china[0][0]\n",
    "newimage = china.reshape((427 * 640, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(newimage).drop_duplicates().shape\n",
    "# 去掉重复值，总共有9万多个颜色\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(china)\n",
    "# 看图片长什么样子， 以上步骤都是处理图像必备的步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再插入一张\n",
    "flower = load_sample_image(\"flower.jpg\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用kmeans把9万多个颜色聚类到64个颜色，不损失太多的图片信息，就是把64个质心替换簇内的其他样本\n",
    "n_clusters = 64\n",
    "# plt.imshow再浮点数上表现非常优异，在这里我们把浮点数压缩到0 1 之间\n",
    "china = np.array(china, dtype=np.float64) / china.max()\n",
    "# 把china 从图片格式转换为矩阵格式，把三维数组转换为二维矩阵\n",
    "# 把长宽高都先取出来，之后输入时只能输入二维数组，但是最后在imshow还是要以后用三维输出，是一种存储\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3, \"一个格子中的特征数不等于3\"\n",
    "# assert 相当于raise error if not ，表示为“不为true就报错”\n",
    "# 要求d必须为三，否则就报错\n",
    "# np.reshape(a, newshape, order=\"C\"), reshape函数的第一个参数a是要改变结构的对象，第二个参数是要改变的新结构\n",
    "image_array = np.reshape(china, (w * h, d))# reshape改变结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_array\n",
    "image_array.shape\n",
    "# 无论有几维，只要相乘后的总数量不变，维度就可以随意变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来进行建模\n",
    "# 收先先使用1000个数据找到初始质心\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(image_array_sample)\n",
    "kmeans.cluster_centers_\n",
    "# 选出来64个质心\n",
    "# 选出质心之后，按照已经存在的质心对所有数据进行聚类\n",
    "labels = kmeans.predict(image_array)\n",
    "labels.shape# (273280,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels)\n",
    "# 使用质心来替换所有的样本,并且不破坏原有的数据\n",
    "image_kmeans = image_array.copy()\n",
    "image_kmeans # 27w 个样本点，9w多种不同的颜色（像素点）\n",
    "labels # 这27万个样本点对应的额簇的质心的索引\n",
    "#kmeans.cluster_centers_[labels[0]]\n",
    "# 把对应的质心都取出来，到一个数组里\n",
    "for i in range(w*h):\n",
    "    image_kmeans[i] = kmeans.cluster_centers_[labels[i]]\n",
    "# 查看生成的新图片信息\n",
    "image_kmeans.shape# 273280, 3\n",
    "pd.DataFrame(image_kmeans).drop_duplicates().shape\n",
    "# 64, 3\n",
    "# 恢复图片结构\n",
    "image_kmeans = image_kmeans.reshape(w, h, d)\n",
    "image_kmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机进行的矢量量化\n",
    "centroid_random = shuffle(image_array, random_state=0)[:n_clusters]# 从中随机抽出64个数字作为质心\n",
    "labels_random = pairwise_distances_argmin(centroid_random,image_array,axis=0)\n",
    "# x1和x2分别是序列\n",
    "#用来计算x2中的每个样本点的距离，并返回和x2相同形状的，x1 中对应的最近的样本点的索引\n",
    "# 就是对每个点都计算和64个质心的距离，返回最近的质心的索引,代表这27万对应的随机质心是哪一个\n",
    "labels_random\n",
    "len(set(labels_random))\n",
    "#使用随机质心代替所有样本\n",
    "image_random = image_array.copy()\n",
    "for i in range(w * h):\n",
    "    image_array[i] = centroid_random[labels_random[i]]\n",
    "# 恢复图片形状\n",
    "image_random = image_random.reshape(w, h, d)\n",
    "image_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看两种方式的区别\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"original image,9w颜色\")\n",
    "plt.imshow(china)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"kmeans\")\n",
    "plt.imshow(image_kmeans)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"random\")\n",
    "plt.imshow(image_random)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}