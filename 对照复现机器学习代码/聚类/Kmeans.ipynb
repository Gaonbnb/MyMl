{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最好首先对数据进行可视化，这样分为多少个类心里有个印象\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 自己创建数据集\n",
    "X, y = make_blobs(n_samples=500, n_features=2, centers=4, random_state=1)\n",
    "# 生成1个子图，fig是画布，ax1是对象\n",
    "fig, ax1 = plt.subplots(1)\n",
    "ax1.scatter(X[:, 0], X[:, 1]\n",
    "            ,marker=\"o\" # 点的形状\n",
    "            ,s=8 # 点的大小\n",
    "            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 3\n",
    "\n",
    "cluster = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "\n",
    "# 重要的属性labels_, 查看聚类好的类别，每个样本所对应的类\n",
    "y_pred = cluster.labels_\n",
    "y_pred\n",
    "# kmeams并不需要建立模型或者预测结果，因此我们只需要fit就能得到聚类结果了\n",
    "# 也有predict表示学习数据x并对x的类进行预测,但是和我们的labels属性结果相同\n",
    "pre = cluster.fit_predict(X)\n",
    "pre == y_pred\n",
    "# 当数据量很大时，就需要predict，可以先用切片，切少量的样本，用fit找到质心，之后再将所有数据带入跑，就会比较好,比如很多万行\n",
    "cluster_smallsub = KMeans(n_clusters=n_clusters, random_state=0).fit(X[:200])\n",
    "y_pred_ = cluster_smallsub.predict(X)\n",
    "# 查看质心\n",
    "centroid = cluster.cluster_centers_\n",
    "centroid\n",
    "\n",
    "# 查看总距离的平方和\n",
    "inertia = cluster.inertia_\n",
    "inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [\"red\", \"pink\", \"orange\", \"gray\"]\n",
    "fig, ax1 = plt.subplots(1)\n",
    "for i in range(n_clusters):\n",
    "    ax1.scatter(X[y_pred==i, 0], X[y_pred==i, 1]\n",
    "                ,marker=\"o\"\n",
    "                ,s=8\n",
    "                ,c=color[i])\n",
    "ax1.scatter(centroid[:, 0], centroid[:, 1]\n",
    "            ,marker=\"x\"\n",
    "            ,s=15\n",
    "            ,c=\"black\")\n",
    "plt.show()\n",
    "# 接下来可以改变n_cluster，来看看，发现平方和不是评价指标，毕竟取500 的平方和是0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何评价聚类呢，无法确定，只能是根据业务来看，inartia没有界，对模型本身是好不好，而且本身容易受到特征数目的影响，会陷入维度诅咒，会受到超参数k的影响，而且假设是个凸分布\n",
    "# 使用轮廓系数\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "# 把数据和对应的预测类别带入进行分析\n",
    "silhouette_score(X, y_pred)\n",
    "# 平均的样本轮廓系数\n",
    "silhouette_score(X, cluster.labels_)\n",
    "# 每个样本自己的轮廓系数\n",
    "silhouette_samples(X, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  另一个评价指数\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "calinski_harabaz_score(X, y_pred)\n",
    "# 为了计算速度，有%%timeit 魔法方法\n",
    "# 这里我们用另一种计算时间的方法，时间戳计算运行速度\n",
    "from time import time\n",
    "# time(),记下每一次time（）命令的时间戳\n",
    "t0 = time()\n",
    "calinski_harabaz_score(X, y_pred)\n",
    "time() - t0\n",
    "\n",
    "t0 = time()\n",
    "silhouette_score(X, y_pred)\n",
    "time() - t0\n",
    "# 时间戳可以通过datatime中的函数转换为真正的时间格式\n",
    "import datetime\n",
    "datetime.datetime.fromtimestamp(t0).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  }
 ]
}