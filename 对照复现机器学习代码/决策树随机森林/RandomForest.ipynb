{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林\n",
    "# 整个环境有利于画图\n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "wine.data.shape\n",
    "wine.target\n",
    "# 实例化\n",
    "# 训练集导入实例化后的模型进行训练，使用的接口是fit\n",
    "# 使用其他接口将测试集导入\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(wine.data, wine.target, test_size=0.3)\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "rfc.fit(x_train, y_train)\n",
    "score_c = clf.score(x_valid, y_valid)\n",
    "score_r = rfc.score(x_valid, y_valid)\n",
    "print(\"Single Tree:{}\".format(score_c))\n",
    "print(\"Random Forest:{}\".format(score_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "rfc = RandomForestClassifier(n_estimators=25)\n",
    "rfc_s = cross_val_score(rfc, wine.data, wine.target, cv=10)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf_s = cross_val_score(clf, wine.data, wine.target, cv=10)\n",
    "\n",
    "plt.plot(range(1, 11), rfc_s, label=\"RandomForest\")\n",
    "plt.plot(range(1, 11), clf_s, label=\"DecisionTreeClassifier\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "##########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解释为什么随机森林牛批\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "# comb 是组合\n",
    "np.array([comb(25, i) * (0.2 ** i) * (1 - 0.2) ** (25 - i) for i in range(13, 26)]).sum()\n",
    "rfc = RandomForestClassifier(n_estimators=25, random_state=2)\n",
    "rfc = rfc.fit(x_train, y_train)\n",
    "\n",
    "# extimators_是看树的本身的状况，[0]是取第一颗树\n",
    "rfc.estimators_[0].random_state\n",
    "#rfc.estimators[]是tree的类型，放到dataframe里面会使模型消失\n",
    "for i in range(len(rfc.estimators_)):\n",
    "    print(rfc.estimators_[i].random_state) \n",
    "\n",
    "# oob方法测试,无需划分训练集和测试集\n",
    "rfc = RandomForestClassifier(n_estimators=25, oob_score=True)\n",
    "rfc = rfc.fit(wine.data, wine.target)\n",
    "# 重要属性oob_score_\n",
    "rfc.oob_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging相关\n",
    "import numpy as np\n",
    "x = np.linspace(0, 1, 20)\n",
    "y = []\n",
    "\n",
    "for epsilon in np.linspace(0, 1, 20):\n",
    "    E = np.array([comb(25, i) * (epsilon ** i) * ((1 - epsilon) ** (25 - i)) for i in range(13, 26)]).sum()\n",
    "    y.append(E)\n",
    "plt.plot(x, y, 'o-', label='when estimators are different')\n",
    "plt.plot(x, x, '--', label='if all estimators are same')\n",
    "plt.xlabel(\"individual estimator's error\")\n",
    "plt.ylabel(\"RandomForest's error\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林随机树\n",
    "from sklearn.datasets import load_boston # 一个标签是连续性变量的数据集，字典\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "boston = load_boston()\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0) #实例化\n",
    "cross_val_score(regressor, boston.data, boston.target, cv=10, scoring='neg_mean_squared_error') #交叉验证\n",
    "#import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())# sklearn.metrics sklearn中的模型评估（打分）指标列表,忘了指标可以用这个查找\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补随机值\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "dataset = load_boston()\n",
    "dataset.data.shape\n",
    "# 总共506*13\n",
    "x_full, y_full = dataset.data, dataset.target\n",
    "n_samples = x_full.shape[0]\n",
    "n_features = x_full.shape[1]\n",
    "# 首先我们需要确定我们希望放入的缺失数据的比例，在这里我们假设是50%，那总共要有3289个缺失值\n",
    "rng = np.random.RandomState(0)# 确认一种随机模式，数字随便搞\n",
    "missing_rate = 0.5\n",
    "#np.floor 向下取整，但是返回浮点数\n",
    "n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))\n",
    "# 所有数据要随机遍布在数据集的各行各列中，每一个缺失值会需要一个行索引和一个列索引\n",
    "# 如果能够创造一个数组，包含3289个分布再0-506中间的行索引，和3289个分布在0-13之间的列索引\n",
    "# 那我们就可以利用索引来为数据中的任意3289个位置赋空值\n",
    "# 然后我们用0，均值和随机森林来填写这些缺失值，然后查看回归的结果如何\n",
    "\n",
    "missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "missing_samples = rng.randint(0, n_samples, n_missing_samples)\n",
    "\n",
    "#missing_samples = rng.choice(dataset.data.shape[0], n_missing_samples, replace=False)\n",
    "# 采样了3289个数据，远远超过我们的样本量，所以我们使用随机抽取，若是我们需要的数据量小于我们的样本量，\n",
    "#那可以。random.choice不重复抽样，使得数据更加分散，不会集中在某些行中\n",
    "# replace=false 请不要重复\n",
    "\n",
    "# 不改变本身\n",
    "x_missing = x_full.copy()\n",
    "y_missing = y_full.copy()\n",
    "\n",
    "x_missing[missing_samples, missing_features] = np.nan\n",
    "# 转换成dataframe为了后续便于操作，numpy矩阵运算超快，但是索引确实不好用\n",
    "x_missing = pd.DataFrame(x_missing)\n",
    "# 使用均值和0进行填补\n",
    "from sklearn.impute import SimpleImputer\n",
    "# 空值怎么表示，策略是mean，还可以填其他的\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "# 训练fit+导出predict 》》》特殊接口fit_transform\n",
    "x_missing_mean = imp_mean.fit_transform(x_missing)\n",
    "\n",
    "#x_missing_mean.isnull() #错误因为是ndarry\n",
    "pd.DataFrame(x_missing_mean).isnull().sum()\n",
    "#布尔值 false = 0， true = 1\n",
    "\n",
    "# 使用0进行填补,constant表示填充策略是常数\n",
    "imp_0 = SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=0)\n",
    "x_missing_0 = imp_0.fit_transform(x_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用随机森林填充缺失值\n",
    "任何回归都是从矩阵中学习，然后求解连续型标签y的过程，因为算法认为矩阵与标签之间存在某种联系。\n",
    "实际上标签和特征是可以相互转化的，比如地区预测房价，也可以房价预测地区。回归填补缺失值正是利用这个思想\n",
    "对于一个有n维他特征的数据，特征r有缺失值，把r当作标签，其他n-1个特征和原本的标签组成新的特征矩阵，r没缺失的部分就是y_train,可以作为标签，缺失的就是我们要预测的部分\n",
    "特征r不缺失的值对应其他n-1个他特征和本来的标签作为x-train，特征r不确实的值y-train\n",
    "特征r缺失的值对应其他n-1个他特征和本来的标签作为x-valid，特征r确实的值y-valid\n",
    "这种情况对某一个特征大量缺失其他特征完整非常适用\n",
    "如果除了特征r，其他特征很完整的话，？\n",
    "答案是遍历所有特征，从缺失值最少的开始填补（需要准确性特征最少）\n",
    "填补一个特征时，先将其他特征缺失值用0代替，没完成一次回归，就将预测值放到原本的特征阵中，在继续填补下一个特征。不断完整矩阵\n",
    "\"\"\"\n",
    "x_missing_reg = x_missing.copy()\n",
    "#  找出数据中，缺失值从小到大排列的特征的顺序\n",
    "sortindex = np.argsort(x_missing_reg.isnull().sum(axis=0)).values\n",
    "# argsort 会返回从小到大排序的顺序所对应的索引，。values就是把索引给取出来\n",
    "# sort就直接给每个缺失值是多少的排序，但没有索引 axis=0 就是对行相加操作，axis=1就是对列相加操作\n",
    "\n",
    "####开始填充\n",
    "\n",
    "# 下面的填充从小到多，这里可以自己还原\n",
    "for i in sortindex:\n",
    "\n",
    "# 构建我们的新特征矩阵和新标签（没有被选中的填充的特征+原始的标签）和新标签（被选中去填充的标签）\n",
    "# 复制一个表是用来填0的\n",
    "df = x_missing_reg\n",
    "\n",
    "fillc = df.iloc[:, 6]\n",
    "# 新特征矩阵 df.columns返回列索引, 连链接起来，dataframe（y_full）也变成这个类型. 左右拼起来\n",
    "df = pd.concat([df.iloc[:, df.columns != 6], pd.DataFrame(y_full)], axis=1)\n",
    "# 在新特征矩阵中，对含有缺失值的列，进行0的填补，实例化，训练加导出\n",
    "df_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0).fit_transform(df) \n",
    "# 找出我们的训练集和测试集\n",
    "# 是被选中的要填充的特征中（现在是我们的标签），存在的那些值，非空值\n",
    "y_train = fillc[fillc.notnull()]\n",
    "# fillc.isnull()返回的是true和false\n",
    "y_valid = fillc[fillc.isnull()]\n",
    "# 在新特征矩阵上，被选出来的要填充的特征的非空值所对应的记录\n",
    "x_train = df_0[y_train.index, :]\n",
    "x_valid = df_0[y_valid.index, :]\n",
    "\n",
    "# 用随机森林回归来填补缺失值\n",
    "rfc = RandomForestRegressor(n_estimators=100)\n",
    "rfc = rfc.fit(x_train, y_train)\n",
    "y_predict = rfc.predict(x_valid) # 就是我们要填写空值的那些值\n",
    "# 将补好的特征返回到我们的原始特征矩阵中\n",
    "# pd.DataFrame(df_0)\n",
    "x_missing_reg.loc[x_missing_reg.iloc[:, 6].isnull(), 6] = y_predict\n",
    "\n",
    "# x_missing_reg.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 合成的最终程序\n",
    "x_missing_reg = x_missing.copy()\n",
    "#  找出数据中，缺失值从小到大排列的特征的顺序\n",
    "sortindex = np.argsort(x_missing_reg.isnull().sum(axis=0)).values\n",
    "# argsort 会返回从小到大排序的顺序所对应的索引，。values就是把索引给取出来\n",
    "# sort就直接给每个缺失值是多少的排序，但没有索引 axis=0 就是对行相加操作，axis=1就是对列相加操作\n",
    "\n",
    "####开始填充\n",
    "\n",
    "# 下面的填充从小到多，这里可以自己还原\n",
    "for i in sortindex:\n",
    "\n",
    "    # 构建我们的新特征矩阵和新标签（没有被选中的填充的特征+原始的标签）和新标签（被选中去填充的标签）\n",
    "    # 复制一个表是用来填0的\n",
    "    df = x_missing_reg\n",
    "\n",
    "    fillc = df.iloc[:, i]\n",
    "    # 新特征矩阵 df.columns返回列索引, 连链接起来，dataframe（y_full）也变成这个类型. 左右拼起来\n",
    "    df = pd.concat([df.iloc[:, df.columns != i], pd.DataFrame(y_full)], axis=1)\n",
    "    # 在新特征矩阵中，对含有缺失值的列，进行0的填补，实例化，训练加导出\n",
    "    df_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0).fit_transform(df) \n",
    "    # 找出我们的训练集和测试集\n",
    "    # 是被选中的要填充的特征中（现在是我们的标签），存在的那些值，非空值\n",
    "    y_train = fillc[fillc.notnull()]\n",
    "    # fillc.isnull()返回的是true和false\n",
    "    y_valid = fillc[fillc.isnull()]\n",
    "    # 在新特征矩阵上，被选出来的要填充的特征的非空值所对应的记录\n",
    "    x_train = df_0[y_train.index, :]\n",
    "    x_valid = df_0[y_valid.index, :]\n",
    "\n",
    "    # 用随机森林回归来填补缺失值\n",
    "    rfc = RandomForestRegressor(n_estimators=100)\n",
    "    rfc = rfc.fit(x_train, y_train)\n",
    "    y_predict = rfc.predict(x_valid) # 就是我们要填写空值的那些值\n",
    "    # 将补好的特征返回到我们的原始特征矩阵中\n",
    "    # pd.DataFrame(df_0)\n",
    "    x_missing_reg.loc[x_missing_reg.iloc[:, i].isnull(), i] = y_predict\n",
    "\n",
    "    # x_missing_reg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########对比几种模型\n",
    "X = [x_full, x_missing_mean, x_missing_0, x_missing_reg]\n",
    "mse = []\n",
    "for x in X:\n",
    "    estimator = RandomForestRegressor(random_state=0, n_estimators=100)#实例化\n",
    "    scores = cross_val_score(estimator, x, y_full, scoring=\"neg_mean_squared_error\",cv=5).mean()\n",
    "    mse.append(scores * -1)\n",
    "[*zip(['x_full', 'x_missing_mean', 'x_missing_0', 'x_missing_reg'], mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [\n",
    "    'Full data',\n",
    "    'Mean Imputation',\n",
    "    'Zero Imputation',\n",
    "    'Regressor Imputation'\n",
    "]\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = plt.subplot(111)\n",
    "for i in np.arange(len(mse)):\n",
    "    # barh是从左向右找到条形图,align 是条形图的粗\n",
    "    ax.barh(i, mse[i], color=colors[i], alpha=0.6, align=\"center\")\n",
    "ax.set_title('Imputation Techniques with Boston Data')\n",
    "# 因为是横过来的，看左右\n",
    "ax.set_xlim(left=np.min(mse) * 0.9, right=np.max(mse) * 1.1)\n",
    "# 看刻度，有四个刻度\n",
    "ax.set_yticks(np.arange(len(mse)))\n",
    "# \n",
    "ax.set_xlabel('mse')\n",
    "# 这句话没什么用\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_yticklabels(x_labels)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ]
}