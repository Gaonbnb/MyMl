{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wine = load_wine()\n",
    "pd.concat([pd.DataFrame(wine.data), pd.DataFrame(wine.target)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(wine.data, wine.target, test_size=0.3)\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(x_train, y_train)\n",
    "score = clf.score(x_valid, y_valid)\n",
    "score\n",
    "\n",
    "feature_name = ['酒精', '苹果酸', '灰', '灰的碱性', '镁', '总酚', '类黄素', '非黄烷类分类', '花青素', '颜色强度', '色调', '稀释葡萄酒', '脯氨酸']\n",
    "dot_data = tree.export_graphviz(clf\n",
    "                                ,feature_names=feature_name\n",
    "                                ,class_names=[\"琴酒\", \"雪梨\", \"贝尔摩德\"]\n",
    "                                ,filled=True\n",
    "                                ,rounded=True\n",
    "                                )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_\n",
    "[*zip(feature_name, clf.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=30)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "score = clf.score(x_valid, y_valid)\n",
    "score\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\"\n",
    "                                    ,random_state=30\n",
    "                                    ,splitter=\"random\"\n",
    "                                    ,max_depth=3\n",
    "                                    ,min_samples_leaf=10\n",
    "                                    ,min_samples_split=10\n",
    "                                    )\n",
    "clf = clf.fit(x_train, y_train)\n",
    "score = clf.score(x_valid, y_valid)\n",
    "print(score)\n",
    "dot_data = tree.export_graphviz(clf\n",
    "                                ,feature_names=feature_name\n",
    "                                ,class_names=[\"琴酒\", \"雪梨\", \"贝尔摩德\"]\n",
    "                                ,filled=True\n",
    "                                ,rounded=True\n",
    "                                )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(10):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i+1\n",
    "                                        ,criterion=\"entropy\"\n",
    "                                        ,random_state=30\n",
    "                                        ,splitter=\"random\"\n",
    "    )\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_valid, y_valid)\n",
    "    test.append(score)\n",
    "\n",
    "plt.plot(range(1, 11), test, color=\"red\", label=\"max_depth\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "# 交叉验证\n",
    "#cross_val_score(regressor, boston.data, boston.target, cv=10) r^2\n",
    "cross_val_score(regressor, boston.data, boston.target, cv=10\n",
    "                ,scoring=\"neg_mean_squared_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例回归一维数据\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "# 生成随机数种子，是随机稳定\n",
    "rng = np.random.RandomState(1)\n",
    "# 生成0-1,且不能为一维,生成的是二维的80*1矩阵\n",
    "#5 * rng.rand(80, 1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "# y只能有一维数据，ravel（）降维n维变成n-1维。一维数组不分行列\n",
    "y = np.sin(X).ravel()\n",
    "#plt.figure()\n",
    "#plt.scatter(X, y, s=20, edgecolors=\"black\", c=\"darkorange\", label=\"data\")\n",
    "#plt.legend()\n",
    "#不可能搞到完全相同的数据，需要有一些噪声，通过给每个数字加上随机数\n",
    "#np.romdom.rand(数据结构)随机生成随机数\n",
    "y[::5] += 3 * (0.5 - rng.rand(16))\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolors=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X,y)\n",
    "regr_2.fit(X,y)\n",
    "\n",
    "# 测试集,newaxis 用来增维度\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "#l = np.array([1,2,3,4])\n",
    "#l.shape #(4,)\n",
    "#l[:, np.newaxis]\n",
    "#l[:, np.newaxis].shape #(4,1)\n",
    "#l[np.newaxis,:].shape #(1,4)\n",
    "# 预测\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "# 画图\n",
    "plt.figure()\n",
    "# c 点的颜色，edgecolor 边框颜色 s 点的大小\n",
    "plt.scatter(X, y, s=20, edgecolors=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "# 显示图例\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# max_depth=5 有一些过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据在ai studio\n",
    "# 分析泰坦尼克号\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv('data/data/train.csv')\n",
    "# 查看数据集本身的特性\n",
    "#data.info()\n",
    "#data.head()\n",
    "\n",
    "# 乘客的名字，还有登录的仓，票号等与存活关系不大，且缺失值过大的时候直接删除\n",
    "###### 筛选特征 \n",
    "#inplace表示直接对原先的数据进行修改, axis=1 删除列，默认axis=0 删除行\n",
    "data.drop([\"Cabin\", \"Name\", \"Ticket\"], inplace=True, axis=1)\n",
    "#data = data.drop([\"Cabin\", \"Name\", \"ticket\"]) 同上\n",
    "\n",
    "###### 处理缺失值 \n",
    "#年龄缺200行 fillna 填补缺失值\n",
    "data['Age'] = data[\"Age\"].fillna(data[\"Age\"].mean())\n",
    "#enbark两个缺失值，就删掉相应的行,dropna 删除nan\n",
    "data = data.dropna(axis=0)\n",
    "data.info()\n",
    "#data[\"Embarked\"].unique()# 不重复的取值\n",
    "labels = data[\"Embarked\"].unique().tolist()\n",
    "# 把特征换算成0123...,换算索引,这里舱门相互独立，所以直接换\n",
    "data[\"Embarked\"] = data[\"Embarked\"].apply(lambda x: labels.index(x))\n",
    "# int(true) = 1 int(false) = 0\n",
    "#data.loc[:, \"sex\"]取文字切片 iloc[:, 3]数字索引\n",
    "data[\"Sex\"] = (data[\"Sex\"] == \"male\").astype(\"int\") \n",
    "# data.columns返回标签列表\n",
    "x = data.iloc[:, data.columns != \"Survived\"]\n",
    "y = data.iloc[:, data.columns == \"Survived\"]\n",
    "\n",
    "# 开始训练\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3)\n",
    "# 所以这时候索引混乱，最好改一下\n",
    "#索引改成排序了\n",
    "#x_train.index = range(x_train.shape[0])\n",
    "for i in [x_train, x_valid, y_train, y_valid]:\n",
    "    i.index = range(i.shape[0])\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=25)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "score = clf.score(x_valid, y_valid)\n",
    "score\n",
    "#0.71\n",
    "\n",
    "# 有交叉验证\n",
    "clf = DecisionTreeClassifier(random_state=25)\n",
    "#交叉验证会输出10个结果的列表\n",
    "#score = cross_val_score(clf, x, y, cv=10).mean()\n",
    "#score\n",
    "#0.75\n",
    "\n",
    "# 调参\n",
    "tr = []\n",
    "te = []\n",
    "# 只有random和max_depth\n",
    "for i in range(10):\n",
    "    clf = DecisionTreeClassifier(random_state=25\n",
    "                                ,max_depth=i+1\n",
    "                                ,criterion=\"entropy\"\n",
    "                                )\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    score_tr = clf.score(x_train, y_train)\n",
    "    score_te = cross_val_score(clf, x, y, cv=10).mean()\n",
    "    tr.append(score_tr)\n",
    "    te.append(score_te)\n",
    "print(max(te))\n",
    "plt.plot(range(1, 11), tr, color=\"red\",label=\"train\")\n",
    "plt.plot(range(1, 11), te, color=\"blue\", label=\"test\")\n",
    "plt.xticks(range(1, 11))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# 过拟合很严重\n",
    "\n",
    "# 先换entropy试一试\n",
    "\n",
    "# 网格搜索是能够同时调整多个参数的技术，是个枚举技术，底层把所有参数带入，所以计算量非常大，时间很长。而且不一定比自己写的跑的好\n",
    "#np.linspace(0, 0.5, 50)# 生成50个随机的有顺序的数\n",
    "#gini_threholds = np.linspace(0, 0.5, 50)\n",
    "#entropy_threholds = np.linspace(0, 1, 50)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=25)\n",
    "\n",
    "# 一些参数和这些参数对应的，我们希望网格搜索来搜索的取值范围\n",
    "\n",
    "\n",
    "\n",
    "# min_impurity_decrease非常不容易定出来\n",
    "parameters = {\"criterion\":(\"gini\", \"entropy\")\n",
    "                ,\"splitter\": (\"best\", \"random\")\n",
    "                ,\"max_depth\":[*range(1,10)]\n",
    "                ,\"min_samples_leaf\":[*range(1,50,5)]\n",
    "                ,\"min_impurity_decrease\":[*np.linspace(0, 0.5, 50)]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=25)\n",
    "# GS同时fit sxore 和交叉验证三种功能\n",
    "GS = GridSearchCV(clf, parameters, cv=10)\n",
    "GS = GS.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "GS.best_params_ #从我们输入的参数和参数取值的列表中，返回最佳组合\n",
    "GS.best_score_ #网络搜索后的模型的评判标准"
   ]
  }
 ]
}